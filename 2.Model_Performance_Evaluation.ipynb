{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f3975f-d797-438c-ba83-6e97d0754e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T02:52:42.759903Z",
     "iopub.status.busy": "2024-08-14T02:52:42.759437Z",
     "iopub.status.idle": "2024-08-14T02:52:44.390429Z",
     "shell.execute_reply": "2024-08-14T02:52:44.388614Z",
     "shell.execute_reply.started": "2024-08-14T02:52:42.759871Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import joblib\n",
    "import random\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, KMeansSMOTE, SVMSMOTE, BorderlineSMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import matthews_corrcoef, average_precision_score, roc_auc_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983a995b-92f3-46c2-b915-13df999c6109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T02:52:44.391889Z",
     "iopub.status.busy": "2024-08-14T02:52:44.391549Z",
     "iopub.status.idle": "2024-08-14T02:52:44.404865Z",
     "shell.execute_reply": "2024-08-14T02:52:44.403652Z",
     "shell.execute_reply.started": "2024-08-14T02:52:44.391866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "X_train, y_train = joblib.load('train_data.pkl')\n",
    "X_test, y_test = joblib.load('test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2edf1efe-9382-43c3-ac33-2db9baaa0a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T02:52:44.406009Z",
     "iopub.status.busy": "2024-08-14T02:52:44.405796Z",
     "iopub.status.idle": "2024-08-14T02:52:44.422436Z",
     "shell.execute_reply": "2024-08-14T02:52:44.421203Z",
     "shell.execute_reply.started": "2024-08-14T02:52:44.405989Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_sampling(X_train, y_train, method, strategy):\n",
    "    # Define different resampling methods\n",
    "    samplers = {\n",
    "        'ROS': RandomOverSampler(sampling_strategy=strategy, random_state=42),\n",
    "        'SMOTE': SMOTE(sampling_strategy=strategy, random_state=42),\n",
    "        'ADASYN': ADASYN(sampling_strategy=strategy, random_state=42),\n",
    "        'KMeansSMOTE': KMeansSMOTE(sampling_strategy=strategy, random_state=42, cluster_balance_threshold=-0.5),\n",
    "        'SVMSMOTE': SVMSMOTE(sampling_strategy=strategy, random_state=42),\n",
    "        'BorderlineSMOTE': BorderlineSMOTE(sampling_strategy=strategy, random_state=42),\n",
    "        'SMOTEENN': SMOTEENN(sampling_strategy=strategy, random_state=42),\n",
    "    }\n",
    "\n",
    "    if method == 'IWGMM':\n",
    "        # Implement the Inversely Weighted Gaussian Mixture Model (IWGMM) for resampling\n",
    "        n_components = 6\n",
    "        random_state = 42\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=random_state)\n",
    "        gmm.fit(X_train[y_train == 1])\n",
    "\n",
    "        weights = gmm.weights_\n",
    "        inverse_weights = 1 / weights\n",
    "        inverse_weights /= np.sum(inverse_weights)\n",
    "        gmm.weights_ = inverse_weights\n",
    "\n",
    "        num_positive_samples_original = np.sum(y_train == 1)\n",
    "        num_negative_samples_original = np.sum(y_train == 0)\n",
    "\n",
    "        desired_positive_samples = int(num_negative_samples_original * strategy)\n",
    "\n",
    "        num_new_samples = max(desired_positive_samples - num_positive_samples_original, 0)\n",
    "        np.random.seed(random_state)\n",
    "        new_positive_samples = gmm.sample(num_new_samples)[0]\n",
    "\n",
    "        X_positive_resampled = np.vstack((X_train[y_train == 1], new_positive_samples))\n",
    "        y_positive_resampled = np.ones(X_positive_resampled.shape[0])\n",
    "        X_resampled = np.vstack((X_train[y_train == 0], X_positive_resampled))\n",
    "        y_resampled = np.hstack((y_train[y_train == 0], y_positive_resampled))\n",
    "\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=random_state)\n",
    "        return X_resampled, y_resampled\n",
    "\n",
    "    elif method in samplers:\n",
    "        # Use predefined samplers for resampling\n",
    "        sampler = samplers[method]\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "        return X_resampled, y_resampled\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported sampling method\")\n",
    "\n",
    "def evaluate_model_with_sampling(X_train, y_train, X_test, y_test, model_name, sampling_method):\n",
    "    models = {\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=1),\n",
    "        'RF': RandomForestClassifier(random_state=1),\n",
    "        'GBDT': GradientBoostingClassifier(random_state=1),\n",
    "        'XGBoost': xgboost.XGBClassifier(random_state=1),\n",
    "        'CatBoost': CatBoostClassifier(random_state=1, verbose=0),\n",
    "        'LightGBM': LGBMClassifier(random_state=1)\n",
    "    }\n",
    "\n",
    "    clf = models[model_name]\n",
    "    results = []\n",
    "\n",
    "    # Define a list of sampling strategies to evaluate\n",
    "    # This list spans from 0.05 to 1.01, incremented by 0.01, ensuring the inclusion of 1.00.\n",
    "    # It allows for a comprehensive assessment across the entire range of minority-to-majority ratios,\n",
    "    # from very low to perfect balance, to examine the full impact of resampling on model performance.\n",
    "    strategy_list = np.arange(0.05, 1.01, 0.01)\n",
    "    \n",
    "    for strategy in strategy_list:\n",
    "        try:\n",
    "            X_resampled, y_resampled = apply_sampling(X_train, y_train, sampling_method, strategy)\n",
    "            \n",
    "            clf.fit(X_resampled, y_resampled)\n",
    "            p_predict = clf.predict(X_test)\n",
    "            p_predict_proba = clf.predict_proba(X_test)\n",
    "\n",
    "            result = {\n",
    "                'resampling': sampling_method,\n",
    "                'mmr': strategy,\n",
    "                'eml': model_name,\n",
    "                'gmean': geometric_mean_score(y_test, p_predict),\n",
    "                'mcc': matthews_corrcoef(y_test, p_predict),\n",
    "                'ap': average_precision_score(y_test, p_predict_proba[:, 1]),\n",
    "                'auc': roc_auc_score(y_test, p_predict_proba[:, 1]),\n",
    "             }\n",
    "            results.append(result)\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Unable to perform resampling with strategy {strategy}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e48e69-36d9-4e6f-930f-e01e724095af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T02:52:44.423392Z",
     "iopub.status.busy": "2024-08-14T02:52:44.423192Z",
     "iopub.status.idle": "2024-08-14T02:56:10.519077Z",
     "shell.execute_reply": "2024-08-14T02:56:10.518456Z",
     "shell.execute_reply.started": "2024-08-14T02:52:44.423374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform model evaluation of all sampling methods\n",
    "sampling_methods = ['ROS', 'SMOTE', 'ADASYN', 'KMeansSMOTE', 'SVMSMOTE', 'BorderlineSMOTE', 'SMOTEENN', 'IWGMM']\n",
    "models = ['AdaBoost', 'RF', 'GBDT', 'XGBoost', 'CatBoost', 'LightGBM']\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for sampling_method in sampling_methods:\n",
    "    for model in models:\n",
    "        evaluation_scores = evaluate_model_with_sampling(X_train, y_train, X_test, y_test, model, sampling_method)\n",
    "        all_results.append(evaluation_scores)\n",
    "\n",
    "# Combine all results into one DataFrame and save as CSV file\n",
    "df_all_results = pd.concat(all_results)\n",
    "df_all_results.to_csv('all_evaluations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical",
   "language": "python",
   "name": "clinical"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
